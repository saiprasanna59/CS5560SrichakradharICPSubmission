{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.sql import SparkSession\n",
    "# creating spark session\n",
    "spark = SparkSession.builder.appName(\"TfIdf Example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, sentence: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating spark dataframe wiht the input data. You can also read the data from file. label represents the 3 documnets (0.0,0.1,0.2)\n",
    "sentenceData = spark.createDataFrame([\n",
    "        (0.0, \"Welcome to KDM TF_IDF Tutorial.\"),\n",
    "        (0.1, \"Learn Spark ml tf_idf in today's lab.\"),\n",
    "        (0.2, \"Spark Mllib has TF-IDF.\")\n",
    "    ], [\"label\", \"sentence\"])\n",
    "sentenceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, sentence: string, words: array<string>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tokens/words from the sentence data\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(sentenceData)\n",
    "\n",
    "wordsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HashingTF_522136181a00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying tf on the words data\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "# alternatively, CountVectorizer can also be used to get term frequency vectors\n",
    "\n",
    "hashingTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, sentence: string, words: array<string>, rawFeatures: vector]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDF_92916260a260"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, sentence: string, words: array<string>, rawFeatures: vector, features: vector]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(20,[2,8,13,15,17...|\n",
      "|  0.1|(20,[2,3,6,7],[0....|\n",
      "|  0.2|(20,[6,14,15],[0....|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying the results\n",
    "rescaledData.select(\"label\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, words: array<string>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "#creating dataframe of input\n",
    "wordDataFrame = spark.createDataFrame([\n",
    "    (0, [\"Hi\", \"I\", \"heard\", \"about\", \"Spark\"]),\n",
    "    (1, [\"I\", \"wish\", \"Java\", \"could\", \"use\", \"case\", \"classes\"]),\n",
    "    (2, [\"Logistic\", \"regression\", \"models\", \"are\", \"neat\"])\n",
    "], [\"id\", \"words\"])\n",
    "\n",
    "wordDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, words: array<string>, ngrams: array<string>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating NGrams with n=2 (two words)\n",
    "ngram = NGram(n=2, inputCol=\"words\", outputCol=\"ngrams\")\n",
    "ngramDataFrame = ngram.transform(wordDataFrame)\n",
    "ngramDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------+\n",
      "|ngrams                                                            |\n",
      "+------------------------------------------------------------------+\n",
      "|[Hi I, I heard, heard about, about Spark]                         |\n",
      "|[I wish, wish Java, Java could, could use, use case, case classes]|\n",
      "|[Logistic regression, regression models, models are, are neat]    |\n",
      "+------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# displaying the results\n",
    "ngramDataFrame.select(\"ngrams\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: array<string>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "# Input data: Each row is a bag of words from a sentence or document.\n",
    "documentDF = spark.createDataFrame([\n",
    "    (\"McCarthy was asked to analyse the data from the first phase of trials of the vaccine.\".split(\" \"), ),\n",
    "    (\"We have amassed the raw data and are about to begin analysing it.\".split(\" \"), ),\n",
    "    (\"Without more data we cannot make a meaningful comparison of the two systems.\".split(\" \"), ),\n",
    "    (\"Collecting data is a painfully slow process.\".split(\" \"), ),\n",
    "    (\"You need a long series of data to be able to discern such a trend.\".split(\" \"), )\n",
    "], [\"text\"])\n",
    "\n",
    "documentDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: array<string>, result: vector]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learn a mapping from words to Vectors.\n",
    "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"text\", outputCol=\"result\")\n",
    "model = word2Vec.fit(documentDF)\n",
    "result = model.transform(documentDF)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: [McCarthy, was, asked, to, analyse, the, data, from, the, first, phase, of, trials, of, the, vaccine.] => \n",
      "Vector: [0.035033310727158096,-0.032570564886555076,-0.004972728493157774]\n",
      "\n",
      "Text: [We, have, amassed, the, raw, data, and, are, about, to, begin, analysing, it.] => \n",
      "Vector: [0.012736818824823087,-0.005370451047873268,-0.03244196294018856]\n",
      "\n",
      "Text: [Without, more, data, we, cannot, make, a, meaningful, comparison, of, the, two, systems.] => \n",
      "Vector: [0.03442936315416144,0.0062795166785900415,0.04459071166526813]\n",
      "\n",
      "Text: [Collecting, data, is, a, painfully, slow, process.] => \n",
      "Vector: [0.03440210635640791,-0.026394481105463843,-0.0007667035928794315]\n",
      "\n",
      "Text: [You, need, a, long, series, of, data, to, be, able, to, discern, such, a, trend.] => \n",
      "Vector: [-0.034745236734549205,0.02233983635281523,0.0018616045514742534]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in result.collect():\n",
    "    text, vector = row\n",
    "    #printing the results\n",
    "    print(\"Text: [%s] => \\nVector: %s\\n\" % (\", \".join(text), str(vector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|      word|        similarity|\n",
      "+----------+------------------+\n",
      "|       the|0.9785391688346863|\n",
      "|  process.| 0.968315064907074|\n",
      "|       was|0.8777697682380676|\n",
      "|Collecting|0.8135020136833191|\n",
      "|    series|0.7547667622566223|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# showing the synonyms and cosine similarity of the word in input data\n",
    "synonyms = model.findSynonyms(\"data\", 5)   # its okay for certain words , real bad for others\n",
    "synonyms.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
