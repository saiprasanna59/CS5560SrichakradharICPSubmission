{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 News Groups dataset from sklearn open source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text processing\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Data Frame from the Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df = pd.DataFrame(documents, columns=['Headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_clean(text):\n",
    "    \"\"\"\n",
    "    Function to clean text-remove punctuations, lowercase text etc.\n",
    "    \"\"\"\n",
    "    text = re.sub(\"[^a-zA-Z ]\", \"\", text)\n",
    "    text = text.lower()  # lower case text\n",
    "    text = nltk.word_tokenize(text)\n",
    "    return (text)\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['news', 'say','use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do','took','time','year',\n",
    "'done', 'try', 'many', 'some','nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line','even', 'also', 'may', 'take', 'come', 'new','said', 'like','people'])\n",
    "\n",
    "def remove_stop_words(text):\n",
    "     return [word for word in text if word not in stop_words]\n",
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    \"\"\"\n",
    "    Function to stem words\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = [stemmer.stem(word) for word in text]\n",
    "        text = [word for word in text if len(word) > 1] # no single letter words\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def apply_all(text):\n",
    "    \"\"\"\n",
    "    This function applies all the functions above into one\n",
    "    \"\"\"\n",
    "    return stem_words(remove_stop_words(initial_clean(text)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headlines DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well i'm not sure about the story nad it did s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although I realize that principle is not one o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Notwithstanding all the legitimate fuss about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, I will have to change the scoring on my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline\n",
       "0  Well i'm not sure about the story nad it did s...\n",
       "1  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
       "2  Although I realize that principle is not one o...\n",
       "3  Notwithstanding all the legitimate fuss about ...\n",
       "4  Well, I will have to change the scoring on my ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean and tokenize 11314 reviews: 1.34641166528066 min\n",
      "\n",
      "\n",
      "reviews with their respective tokenize version:\n",
      "                                            Headline  \\\n",
      "0  Well i'm not sure about the story nad it did s...   \n",
      "1  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...   \n",
      "2  Although I realize that principle is not one o...   \n",
      "3  Notwithstanding all the legitimate fuss about ...   \n",
      "4  Well, I will have to change the scoring on my ...   \n",
      "\n",
      "                                  tokenized_headline  \n",
      "0  [well, im, sure, stori, nad, bias, whati, disa...  \n",
      "1  [yeah, expect, read, faq, etc, actual, accept,...  \n",
      "2  [although, realiz, principl, one, strongestpoi...  \n",
      "3  [notwithstand, legitim, fuss, propos, muchof, ...  \n",
      "4  [well, chang, score, playoff, pool, unfortunat...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# clean reviews and create new column \"tokenized\"\n",
    "import time\n",
    "t1 = time.time()\n",
    "documents_df['tokenized_headline'] = documents_df['Headline'].apply(apply_all)\n",
    "t2 = time.time()\n",
    "print(\"Time to clean and tokenize\", len(documents_df), \"Headline:\", (t2-t1)/60, \"min\") #Time to clean and tokenize 3209 reviews: 0.21254388093948365 min\n",
    "\n",
    "print('\\n')\n",
    "print(\"Headlines with their respective tokenized versions:\" )\n",
    "print(documents_df.head(5))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 4), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 2), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 4), (57, 1), (58, 1), (59, 1), (60, 1)]]\n",
      "\n",
      "[[('act', 1), ('austria', 1), ('away', 1), ('bias', 1), ('blessingreceiv', 1), ('clearli', 1), ('commit', 1), ('daili', 1), ('degre', 1), ('describ', 1), ('disagre', 1), ('europei', 1), ('exist', 1), ('got', 1), ('govern', 1), ('guiltgo', 1), ('holocaust', 1), ('im', 1), ('incid', 1), ('inhuman', 1), ('isra', 1), ('israel', 2), ('isth', 1), ('jew', 1), ('least', 1), ('live', 1), ('look', 1), ('make', 1), ('media', 4), ('might', 1), ('nad', 1), ('occur', 1), ('ofth', 1), ('one', 1), ('power', 1), ('proisra', 1), ('raceswhen', 1), ('realiz', 1), ('reason', 1), ('redicul', 1), ('report', 2), ('reput', 1), ('shame', 1), ('soldier', 1), ('statement', 1), ('stori', 1), ('subsid', 1), ('sure', 1), ('theatrocitieswhat', 1), ('theeuropean', 1), ('thelett', 1), ('thinkthat', 1), ('toignor', 1), ('toruin', 1), ('treat', 1), ('unfortun', 1), ('us', 4), ('well', 1), ('whati', 1), ('whole', 1), ('world', 1)]]\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "#Create a Gensim dictionary from the tokenized data\n",
    "tokenized = documents_df['tokenized_headline']\n",
    "#Creating term dictionary of corpus, where each unique term is assigned an index.\n",
    "dictionary = corpora.Dictionary(tokenized)\n",
    "#Filter terms which occurs in less than 1 headline and more than 80% of the headlines.\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.8)\n",
    "#convert the dictionary to a bag of words corpus\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in tokenized]\n",
    "print(corpus[:1])\n",
    "print()\n",
    "print([[(dictionary[id], freq) for id, freq in cp] for cp in corpus[:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Now printing the topics and their composition\n",
      "This output shows the Topic-Words matrix for the 7 topics created and the 4 words within each topic\n",
      "(0, '0.008*\"key\" + 0.008*\"use\" + 0.007*\"one\" + 0.005*\"system\"')\n",
      "(1, '0.010*\"god\" + 0.007*\"one\" + 0.006*\"christian\" + 0.005*\"armenian\"')\n",
      "(2, '0.017*\"entri\" + 0.010*\"file\" + 0.008*\"xx\" + 0.005*\"char\"')\n",
      "(3, '0.012*\"game\" + 0.011*\"drive\" + 0.009*\"team\" + 0.008*\"card\"')\n",
      "(4, '0.010*\"file\" + 0.009*\"program\" + 0.008*\"use\" + 0.008*\"window\"')\n",
      "(5, '0.020*\"car\" + 0.011*\"bike\" + 0.006*\"ride\" + 0.005*\"engin\"')\n",
      "(6, '0.009*\"one\" + 0.009*\"dont\" + 0.005*\"well\" + 0.005*\"im\"')\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 7, id2word=dictionary, passes=15)\n",
    "#saving the model\n",
    "ldamodel.save('model_combined.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "print('\\n')\n",
    "print(\"Now printing the topics and their composition\")\n",
    "print(\"This output shows the Topic-Words matrix for the 7 topics created and the 4 words within each topic\")\n",
    "for topic in topics:\n",
    "   print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "first headline is:\n",
      "Well i'm not sure about the story nad it did seem biased. What\n",
      "I disagree with is your statement that the U.S. Media is out to\n",
      "ruin Israels reputation. That is rediculous. The U.S. media is\n",
      "the most pro-israeli media in the world. Having lived in Europe\n",
      "I realize that incidences such as the one described in the\n",
      "letter have occured. The U.S. media as a whole seem to try to\n",
      "ignore them. The U.S. is subsidizing Israels existance and the\n",
      "Europeans are not (at least not to the same degree). So I think\n",
      "that might be a reason they report more clearly on the\n",
      "atrocities.\n",
      "\tWhat is a shame is that in Austria, daily reports of\n",
      "the inhuman acts commited by Israeli soldiers and the blessing\n",
      "received from the Government makes some of the Holocaust guilt\n",
      "go away. After all, look how the Jews are treating other races\n",
      "when they got power. It is unfortunate.\n",
      "\n",
      "\n",
      "\n",
      "The similarity of this review with the topics and respective similarity score are \n",
      "[(1, 0.5368451), (3, 0.014184573), (6, 0.44012618)]\n"
     ]
    }
   ],
   "source": [
    "#finding the similarity of the first review with topics\n",
    "print('\\n')\n",
    "print(\"first headline is:\")\n",
    "print(documents_df.Headline[0])\n",
    "get_document_topics = ldamodel.get_document_topics(corpus[0])\n",
    "print('\\n')\n",
    "print(\"The similarity of this review with the topics and respective similarity score are \")\n",
    "print(get_document_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing topics\n",
    "lda_viz = gensim.models.ldamodel.LdaModel.load('model_combined.gensim')\n",
    "lda_display = pyLDAvis.gensim.prepare(lda_viz, corpus, dictionary, sort_topics=True)\n",
    "pyLDAvis.show(lda_display)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
